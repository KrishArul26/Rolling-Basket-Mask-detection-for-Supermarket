{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.1.2.30 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from opencv-python==4.1.2.30) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python==4.1.2.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.14.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (0.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.22.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (0.1.7)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (3.9.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from tensorflow==1.14.0) (0.36.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (0.7.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.15.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# It loads the classifier uses it to perform object detection on a webcam feed.\n",
    "# It draws boxes and scores around the objects of interest in each frame from\n",
    "# the webcam.\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_graphs/frozen_inference_graph.pb\n"
     ]
    }
   ],
   "source": [
    "detection_graph = tf.Graph()\n",
    "\n",
    "\n",
    "# Import utilites\n",
    "# from utils import label_map_util\n",
    "\n",
    "# Name of the directory containing the object detection module we're using\n",
    "TRAINED_MODEL_DIR = 'frozen_graphs'\n",
    "\n",
    "# Path to frozen detection graph .pb file, which contains the model that is used\n",
    "# for object detection.\n",
    "PATH_TO_CKPT = TRAINED_MODEL_DIR + '/frozen_inference_graph.pb'\n",
    "print(PATH_TO_CKPT)\n",
    "# Path to label map file\n",
    "PATH_TO_LABELS = TRAINED_MODEL_DIR + '/labelmap.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0613 12:56:54.909733 24616 deprecation_wrapper.py:119] From C:\\Users\\ragav\\OneDrive\\Pictures\\discussion\\face_\\utils\\label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'id': 1, 'name': 'with_mask'}, 2: {'id': 2, 'name': 'without_mask'}}\n"
     ]
    }
   ],
   "source": [
    "# Number of classes the object detector can identify\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "print(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ====== Loading frozen graph into memory\n",
      ">  ====== Inference graph loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"> ====== Loading frozen graph into memory\")\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    sess = tf.Session(graph=detection_graph)\n",
    "    print(\">  ====== Inference graph loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'detection_boxes:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499200\n",
      "(1080, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('image3.jpg')\n",
    "image = cv2.resize(image, (1080, 1080))\n",
    "image_expanded = np.expand_dims(image, axis=0)\n",
    "print(image.size)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "(boxes, scores, classes, num) = sess.run(\n",
    "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "            feed_dict={image_tensor: image_expanded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = classes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 2., 2., 2., 2., 1., 2., 2., 1., 1., 2., 2., 1., 2.,\n",
       "       1., 1., 2., 1., 2., 2., 1., 2., 2., 2., 2., 2., 2., 1., 2., 1., 2.,\n",
       "       1., 1., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 2., 2., 1., 1., 1.,\n",
       "       2., 1., 2., 2., 1., 1., 2., 1., 2., 2., 1., 2., 2., 1., 2., 2., 2.,\n",
       "       1., 2., 2., 1., 2., 1., 2., 2., 2., 1., 1., 1., 2., 2., 2., 1., 1.,\n",
       "       2., 1., 1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 2.,\n",
       "       1., 1., 1., 1., 2., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 1., 1.,\n",
       "       2., 1., 2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 1., 2.,\n",
       "       1., 2., 1., 2., 2., 2., 1., 2., 2., 1., 2., 2., 2., 2., 1., 2., 2.,\n",
       "       2., 2., 2., 1., 2., 1., 2., 2., 1., 1., 2., 2., 2., 1., 2., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 2., 2., 2., 2., 1., 2., 2., 1., 1., 2., 2., 1., 2.,\n",
       "       1., 1., 2., 1., 2., 2., 1., 2., 2., 2., 2., 2., 2., 1., 2., 1., 2.,\n",
       "       1., 1., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 2., 2., 1., 1., 1.,\n",
       "       2., 1., 2., 2., 1., 1., 2., 1., 2., 2., 1., 2., 2., 1., 2., 2., 2.,\n",
       "       1., 2., 2., 1., 2., 1., 2., 2., 2., 1., 1., 1., 2., 2., 2., 1., 1.,\n",
       "       2., 1., 1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 2.,\n",
       "       1., 1., 1., 1., 2., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 1., 1.,\n",
       "       2., 1., 2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 1., 2.,\n",
       "       1., 2., 1., 2., 2., 2., 1., 2., 2., 1., 2., 2., 2., 2., 1., 2., 2.,\n",
       "       2., 2., 2., 1., 2., 1., 2., 2., 1., 1., 2., 2., 2., 1., 2., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'with_mask'}, 2: {'id': 2, 'name': 'without_mask'}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "for i in range(len(c)):\n",
    "    if c[i] == 1.:\n",
    "        count_1 = count_1+1\n",
    "    elif c[i] == 2.:\n",
    "        count_2 = count_2+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 2., 2., 2., 2., 1., 2., 2., 1., 1., 2., 2., 1., 2.,\n",
       "       1., 1., 2., 1., 2., 2., 1., 2., 2., 2., 2., 2., 2., 1., 2., 1., 2.,\n",
       "       1., 1., 2., 2., 2., 2., 2., 2., 2., 1., 1., 2., 2., 2., 1., 1., 1.,\n",
       "       2., 1., 2., 2., 1., 1., 2., 1., 2., 2., 1., 2., 2., 1., 2., 2., 2.,\n",
       "       1., 2., 2., 1., 2., 1., 2., 2., 2., 1., 1., 1., 2., 2., 2., 1., 1.,\n",
       "       2., 1., 1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 2.,\n",
       "       1., 1., 1., 1., 2., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 1., 1.,\n",
       "       2., 1., 2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 1., 2.,\n",
       "       1., 2., 1., 2., 2., 2., 1., 2., 2., 1., 2., 2., 2., 2., 1., 2., 2.,\n",
       "       2., 2., 2., 1., 2., 1., 2., 2., 1., 1., 2., 2., 2., 1., 2., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.8826128e-01, 9.8801851e-01, 8.8748783e-01, 2.0485505e-01,\n",
       "       4.8549697e-02, 1.8125683e-02, 8.7946160e-03, 1.7828522e-04,\n",
       "       1.2670735e-04, 8.8133223e-05, 5.4059219e-05, 4.5420398e-05,\n",
       "       1.9386347e-05, 1.5012545e-05, 1.0228662e-05, 4.5813645e-06,\n",
       "       2.5409140e-06, 1.7023957e-06, 1.5871854e-06, 1.0515998e-06,\n",
       "       8.3231561e-07, 6.8115861e-07, 6.6189762e-07, 6.3813002e-07,\n",
       "       6.3160303e-07, 4.4798924e-07, 4.3226180e-07, 3.9838571e-07,\n",
       "       3.2695067e-07, 3.0226812e-07, 2.8255948e-07, 2.5347825e-07,\n",
       "       2.5135535e-07, 2.1521490e-07, 1.8404036e-07, 1.8063265e-07,\n",
       "       1.4873538e-07, 1.2843955e-07, 1.0151435e-07, 9.2066713e-08,\n",
       "       8.5127006e-08, 7.6968647e-08, 5.5803586e-08, 5.3804154e-08,\n",
       "       5.1538272e-08, 4.9754547e-08, 4.1262446e-08, 3.9057706e-08,\n",
       "       3.7031111e-08, 3.4948119e-08, 3.4280532e-08, 3.1269924e-08,\n",
       "       2.1418925e-08, 2.0625192e-08, 1.8492429e-08, 1.6017545e-08,\n",
       "       1.4999010e-08, 1.4476167e-08, 1.3919550e-08, 1.3570081e-08,\n",
       "       1.3557999e-08, 1.3065437e-08, 1.2302131e-08, 1.1175162e-08,\n",
       "       1.1015114e-08, 1.0579381e-08, 1.0044844e-08, 9.9936290e-09,\n",
       "       9.5123172e-09, 9.2806109e-09, 9.0586774e-09, 8.8617718e-09,\n",
       "       8.3650056e-09, 7.8983913e-09, 7.6724431e-09, 7.6448483e-09,\n",
       "       5.6805947e-09, 5.6148415e-09, 5.0743294e-09, 4.8635620e-09,\n",
       "       4.2265755e-09, 4.0729464e-09, 4.0435482e-09, 4.0303658e-09,\n",
       "       3.6254706e-09, 3.4863747e-09, 3.3957086e-09, 3.2385890e-09,\n",
       "       3.0045717e-09, 2.9356146e-09, 2.9301941e-09, 2.7494094e-09,\n",
       "       2.6833793e-09, 2.5474192e-09, 2.4781490e-09, 2.2914892e-09,\n",
       "       2.2770374e-09, 2.1685413e-09, 2.0901727e-09, 1.9899160e-09,\n",
       "       1.8831596e-09, 1.8456268e-09, 1.8324764e-09, 1.6225368e-09,\n",
       "       1.5764607e-09, 1.5599648e-09, 1.4766069e-09, 1.4538002e-09,\n",
       "       1.3950853e-09, 1.3945611e-09, 1.3620484e-09, 1.3566813e-09,\n",
       "       1.2736239e-09, 1.2066251e-09, 1.1553316e-09, 1.0653102e-09,\n",
       "       1.0081980e-09, 9.7335451e-10, 8.6765850e-10, 8.1281065e-10,\n",
       "       7.8600354e-10, 6.7168793e-10, 6.6388278e-10, 6.4226791e-10,\n",
       "       6.1714839e-10, 5.8305077e-10, 5.7892957e-10, 5.7098237e-10,\n",
       "       5.7068950e-10, 5.6496885e-10, 5.5378990e-10, 5.3835314e-10,\n",
       "       5.3277571e-10, 5.2799887e-10, 5.1464949e-10, 5.1187310e-10,\n",
       "       4.4211140e-10, 4.3451140e-10, 4.2633969e-10, 4.1507814e-10,\n",
       "       4.0618814e-10, 3.8912149e-10, 3.8617948e-10, 3.7104178e-10,\n",
       "       3.2943154e-10, 3.2084421e-10, 2.9523972e-10, 2.9258701e-10,\n",
       "       2.8115715e-10, 2.7349828e-10, 2.6622368e-10, 2.6218128e-10,\n",
       "       2.6125127e-10, 2.4425539e-10, 2.4124311e-10, 2.1414208e-10,\n",
       "       2.0776750e-10, 1.9868619e-10, 1.9276877e-10, 1.8939073e-10,\n",
       "       1.8771948e-10, 1.8720031e-10, 1.8643956e-10, 1.7016846e-10,\n",
       "       1.6455901e-10, 1.6150795e-10, 1.6121740e-10, 1.5251447e-10,\n",
       "       1.5088748e-10, 1.5073906e-10, 1.2699750e-10, 1.2643386e-10,\n",
       "       1.1147497e-10, 1.1043882e-10, 1.0833848e-10, 9.7298836e-11,\n",
       "       9.3812805e-11, 9.2651435e-11, 9.1559094e-11, 8.7331475e-11,\n",
       "       8.4984936e-11, 8.2996311e-11, 8.2570784e-11, 8.1927118e-11,\n",
       "       8.1906960e-11, 7.9906491e-11, 7.8774862e-11, 7.8138281e-11,\n",
       "       7.2924208e-11, 6.1136506e-11, 6.0936971e-11, 5.9982505e-11,\n",
       "       5.9645948e-11, 5.9470665e-11, 5.7085576e-11, 5.2699949e-11,\n",
       "       4.7346821e-11, 4.5234181e-11, 4.1751956e-11, 4.1493149e-11,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_util.visualize_boxes_and_labels_on_image_array(image,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.05)\n",
    "    #  cv2.putText(image, text, org, font, fontScale, \n",
    "    #   color, thickness, cv2.LINE_AA, False)\n",
    "    #     cv2.putText(image, \"ALERT\",(0, 180),cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0,255), 2)\n",
    "    #     playsound(r\"alert.wav\")\n",
    "cv2.imshow('Object detector', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = scores.flatten()\n",
    "index = []\n",
    "for i in range(len(sc)):\n",
    "    if sc[i] > 0.05:\n",
    "        index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for ind in index:\n",
    "    print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in index:\n",
    "    \n",
    "    try:\n",
    "        if c[ind] ==1:\n",
    "\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(image,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=8,\n",
    "            min_score_thresh=0.75)\n",
    "            cv2.imshow('Object detector', image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        elif c[ind] ==2:\n",
    "\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(image,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=8,\n",
    "            min_score_thresh=0.75)\n",
    "            cv2.putText(image, \"ALERT\",(0, 180),cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0,255), 2)\n",
    "            playsound(r\"alert.wav\")\n",
    "            cv2.imshow('Object detector', image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        else:\n",
    "            print(\"Here, There is no detection retaled to mask or not mask\")\n",
    "            \n",
    "    except exception as e:\n",
    "        \n",
    "        print(\"Errors\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-2b3592227fb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     vis_util.visualize_boxes_and_labels_on_image_array(image,\n\u001b[0;32m      3\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "if c[ind]==2:\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(image,\n",
    "    np.squeeze(boxes),\n",
    "    np.squeeze(classes).astype(np.int32),\n",
    "    np.squeeze(scores),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    line_thickness=8,\n",
    "    min_score_thresh=0.75)\n",
    "#  cv2.putText(image, text, org, font, fontScale, \n",
    "#   color, thickness, cv2.LINE_AA, False)\n",
    "    cv2.putText(image, \"ALERT\",(0, 180),cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0,255), 2)\n",
    "    playsound(r\"alert.wav\")\n",
    "    cv2.imshow('Object detector', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    print(\"This man not wearing the mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if count_1 > count_2:\n",
    "#     vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#         image,\n",
    "#         np.squeeze(boxes),\n",
    "#         np.squeeze(classes).astype(np.int32),\n",
    "#         np.squeeze(scores),\n",
    "#         category_index,\n",
    "#         use_normalized_coordinates=True,\n",
    "#         line_thickness=8,\n",
    "#         min_score_thresh=0.75)\n",
    "#     cv2.imshow('Object detector', image)\n",
    "#     #cv2.imwrite(\"mask_detection\",image)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "#if count_1 < count_2:\n",
    "\n",
    "vis_util.visualize_boxes_and_labels_on_image_array(image,\n",
    "    np.squeeze(boxes),\n",
    "    np.squeeze(classes).astype(np.int32),\n",
    "    np.squeeze(scores),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    line_thickness=8,\n",
    "    min_score_thresh=0.75)\n",
    "#         cv2.putText(image, text, org, font, fontScale, \n",
    "#                  color, thickness, cv2.LINE_AA, False)\n",
    "\n",
    "cv2.putText(image, \"ALERT\",(0, 180),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0,255), 2)\n",
    "playsound(r\"alert.wav\")\n",
    "cv2.imshow('Object detector', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:661: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'cv::imwrite_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-bfcd5f64d4f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#playsound(r\"C:\\Users\\ragav\\OneDrive\\Pictures\\ineuron notes\\face_\\alert.wav\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#cv2.imshow('Object detector', image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mask_detection\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:661: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'cv::imwrite_'\n"
     ]
    }
   ],
   "source": [
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "image,\n",
    "np.squeeze(boxes),\n",
    "np.squeeze(classes).astype(np.int32),\n",
    "np.squeeze(scores),\n",
    "category_index,\n",
    "use_normalized_coordinates=True,\n",
    "line_thickness=8,\n",
    "min_score_thresh=0.75)\n",
    "#         cv2.putText(image, text, org, font, fontScale, \n",
    "#                  color, thickness, cv2.LINE_AA, False)\n",
    "#cv2.putText(image, \"ALERT\",(0, 180),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0,255), 2)\n",
    "#playsound(r\"C:\\Users\\ragav\\OneDrive\\Pictures\\ineuron notes\\face_\\alert.wav\")\n",
    "#cv2.imshow('Object detector', image)\n",
    "cv2.imwrite(\"mask_detection\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = scores.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.8531950e-01, 9.6755624e-01, 7.6778764e-01, 7.0650077e-01,\n",
       "       6.5854818e-02, 1.4508481e-02, 6.6859573e-03, 5.2119710e-04,\n",
       "       1.3852218e-04, 8.8913162e-05, 4.5148936e-05, 1.5992538e-05,\n",
       "       1.2889884e-05, 1.1196343e-05, 5.5309906e-06, 3.8919916e-06,\n",
       "       3.4511359e-06, 2.5576521e-06, 2.2735542e-06, 1.2982332e-06,\n",
       "       1.2198630e-06, 1.1041413e-06, 7.7285023e-07, 6.9100213e-07,\n",
       "       6.6507420e-07, 5.4950766e-07, 4.4406468e-07, 4.3981109e-07,\n",
       "       2.9679597e-07, 2.6218075e-07, 2.6005816e-07, 2.5327896e-07,\n",
       "       2.4219119e-07, 2.3835821e-07, 2.0868258e-07, 1.8837214e-07,\n",
       "       1.6968279e-07, 1.6018561e-07, 1.2754872e-07, 1.1981201e-07,\n",
       "       1.1499616e-07, 7.3965261e-08, 6.6579304e-08, 6.2130269e-08,\n",
       "       5.3277830e-08, 5.0393094e-08, 4.0113562e-08, 3.6026215e-08,\n",
       "       3.3787639e-08, 3.3666701e-08, 3.1682667e-08, 3.0472350e-08,\n",
       "       2.9701921e-08, 2.6981306e-08, 2.3298675e-08, 2.0578980e-08,\n",
       "       1.9599968e-08, 1.8394424e-08, 1.6780225e-08, 1.5750940e-08,\n",
       "       1.4181694e-08, 1.3622829e-08, 1.3176377e-08, 1.2202694e-08,\n",
       "       1.0364433e-08, 1.0353211e-08, 1.0319636e-08, 9.5453050e-09,\n",
       "       8.9010213e-09, 8.8373309e-09, 8.6330090e-09, 8.4840064e-09,\n",
       "       8.2566292e-09, 8.1136440e-09, 8.0363733e-09, 7.7954354e-09,\n",
       "       7.7817699e-09, 7.7676674e-09, 7.2111130e-09, 6.9680866e-09,\n",
       "       6.7463368e-09, 6.1734058e-09, 5.8647185e-09, 4.9450164e-09,\n",
       "       4.7543152e-09, 4.0637977e-09, 3.9481773e-09, 3.8836019e-09,\n",
       "       3.7358423e-09, 3.6269092e-09, 3.5921557e-09, 3.5532324e-09,\n",
       "       3.1575087e-09, 3.0859950e-09, 2.5432778e-09, 2.3861781e-09,\n",
       "       2.2586710e-09, 2.2575426e-09, 2.1703206e-09, 2.0760242e-09,\n",
       "       2.0001940e-09, 1.9806274e-09, 1.9801214e-09, 1.9426114e-09,\n",
       "       1.7661584e-09, 1.7366688e-09, 1.7299147e-09, 1.7251698e-09,\n",
       "       1.6114062e-09, 1.5390816e-09, 1.4803745e-09, 1.2917130e-09,\n",
       "       1.2894237e-09, 1.2220319e-09, 1.1574380e-09, 1.1385246e-09,\n",
       "       1.1022422e-09, 1.0847501e-09, 1.0565180e-09, 1.0091465e-09,\n",
       "       8.8468882e-10, 8.6450003e-10, 7.7907653e-10, 7.1940198e-10,\n",
       "       6.7766137e-10, 6.2205163e-10, 5.9003274e-10, 5.3653970e-10,\n",
       "       5.1745269e-10, 5.0396032e-10, 4.8414300e-10, 4.7427923e-10,\n",
       "       4.6496479e-10, 4.4906678e-10, 4.4241338e-10, 4.3456941e-10,\n",
       "       4.2932716e-10, 4.1634995e-10, 4.0490411e-10, 3.7830508e-10,\n",
       "       3.7279538e-10, 3.5432482e-10, 3.2557990e-10, 3.1988304e-10,\n",
       "       3.0066338e-10, 2.9449845e-10, 2.9163538e-10, 2.8112926e-10,\n",
       "       2.7837066e-10, 2.5482974e-10, 2.3642502e-10, 2.3612534e-10,\n",
       "       2.3186542e-10, 2.2269037e-10, 2.0504870e-10, 2.0446406e-10,\n",
       "       2.0061265e-10, 1.9925356e-10, 1.9579398e-10, 1.7997935e-10,\n",
       "       1.7440736e-10, 1.7024249e-10, 1.6861218e-10, 1.5923221e-10,\n",
       "       1.5738372e-10, 1.5312920e-10, 1.5030439e-10, 1.3162046e-10,\n",
       "       1.2915718e-10, 1.2048790e-10, 1.1722744e-10, 1.1580955e-10,\n",
       "       9.5108019e-11, 9.2937810e-11, 9.0987037e-11, 9.0942268e-11,\n",
       "       8.5147833e-11, 8.1804695e-11, 7.6685144e-11, 6.8750082e-11,\n",
       "       6.4459445e-11, 6.3473525e-11, 6.2270779e-11, 6.1225199e-11,\n",
       "       6.0924647e-11, 6.0353868e-11, 5.9975067e-11, 5.9862379e-11,\n",
       "       5.9399360e-11, 5.8743628e-11, 5.4569915e-11, 5.2379972e-11,\n",
       "       4.9614313e-11, 4.4871211e-11, 4.0551989e-11, 3.5522734e-11,\n",
       "       3.5420503e-11, 3.3673456e-11, 3.3609227e-11, 3.2537799e-11,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_flat = classes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_boxes = boxes.reshape(300, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_flat2 = np.squeeze(classes).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2,\n",
       "       1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1,\n",
       "       2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2,\n",
       "       1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2,\n",
       "       1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_flat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-4b6839a393f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#                  color, thickness, cv2.LINE_AA, False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Object detector'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in classes_flat2:\n",
    "    if i == 1:\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.75)\n",
    "#         cv2.putText(image, text, org, font, fontScale, \n",
    "#                  color, thickness, cv2.LINE_AA, False)\n",
    "        cv2.imshow('Object detector', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'with_mask'}, 2: {'id': 2, 'name': 'without_mask'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d0fc8fd960dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mplaysound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\ragav\\OneDrive\\Pictures\\ineuron notes\\face_\\alert.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Object detector'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in classes_flat2:\n",
    "    if i == 2:\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.75)\n",
    "#         cv2.putText(image, text, org, font, fontScale, \n",
    "#                  color, thickness, cv2.LINE_AA, False)\n",
    "        cv2.putText(image, \"ALERT\",(0, 180),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0,255), 2)\n",
    "        playsound(r\"C:\\Users\\ragav\\OneDrive\\Pictures\\ineuron notes\\face_\\alert.wav\")\n",
    "        cv2.imshow('Object detector', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hjeeekjekjkjek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.75)\n",
    "    # All the results have been drawn on the frame, so it's time to display it.\n",
    "cv2.imshow('Object detector', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scores.flatten()\n",
    "res = []\n",
    "for idx in range(0, len(result)):\n",
    "    if result[idx] > .40:\n",
    "        res.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.squeeze(classes).astype(np.int32).flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.flatten>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
